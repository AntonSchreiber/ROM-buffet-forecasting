{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition (SVD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.c: evaluate the reconstruction performance on at least two IPSP datasets that were not part of the training\n",
    "\n",
    "1. Load test data sets and U\n",
    "3. Transform the test data into the reduced state with $$ X_{test,reduced} = U_{reduced}^T X_{test} $$\n",
    "4. Reconstruct the reduced test data $ X_{test,reduced} $ with $$ X_{test,reconstr} = U_{reduced} X_{test,reduced}$$\n",
    "5. Compare the reconstructed test set with the original test set using MSE and variance reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "parent_dir = os.path.abspath(join(os.getcwd(), os.pardir))\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "import torch as pt\n",
    "from torch import flatten\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import utils.config as config\n",
    "\n",
    "random.seed(10)\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "DATA_PATH = Path(os.path.abspath('')).parent / \"data\"\n",
    "OUTPUT_PATH = Path(os.path.abspath('')).parent / \"output\" / \"SVD\"\n",
    "\n",
    "TIMESTEP = config.timestep_reconstruction\n",
    "NEW_RES = config.target_resolution\n",
    "\n",
    "test_keys = config.test_keys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load test datasets and U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test datsets\n",
    "X_test_1= pt.load(join(DATA_PATH, \"X_test_1.pt\"))\n",
    "X_test_2 = pt.load(join(DATA_PATH, \"X_test_2.pt\"))\n",
    "\n",
    "# Load left singular vectors\n",
    "U = pt.load(join(OUTPUT_PATH, \"U.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to loop over an increasing number of left singular vectors\n",
    "ranks = range(0, 310, 10)\n",
    "\n",
    "# Initialize lists to save the computed metrics\n",
    "MSE_1 = []\n",
    "MSE_2 = []\n",
    "Var1 = []\n",
    "Var2 = []\n",
    "\n",
    "# compute the total variance test datasets\n",
    "orig_Var1 = pt.var(X_test_1)\n",
    "orig_Var2 = pt.var(X_test_2)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for rank in ranks:\n",
    "    # Compute MSE for test dataset 1\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "    MSE_1.append(F.mse_loss(X_test_1, reconstructed).item())\n",
    "\n",
    "    # Compute variance reconstruction for test dataset 1\n",
    "    Var1.append((1 - ((orig_Var1 - pt.var(reconstructed)) / orig_Var1)) * 100)\n",
    "\n",
    "    # Compute MSE for test dataset 2\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "    MSE_2.append(F.mse_loss(X_test_2, reconstructed).item())\n",
    "\n",
    "    # Compute variance reconstruction for test dataset 2\n",
    "    Var2.append((1 - ((orig_Var2 - pt.var(reconstructed)) / orig_Var2)) * 100)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results and save the figure\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax1.plot(ranks, MSE_1, label=\"Test Dataset 1\")\n",
    "ax1.plot(ranks, MSE_2, label=\"Test Dataset 2\")\n",
    "ax1.set_title(\"MSE\")\n",
    "ax2.plot(ranks, Var1, label=\"Test Dataset 1\")\n",
    "ax2.plot(ranks, Var2, label=\"Test Dataset 2\")\n",
    "ax2.set_title(\"Variance Reconstruction in %\")\n",
    "ax2.set_xlabel(\"rank\")\n",
    "ax2.set_xticks(range(0, 325, 25))\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels)\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"MSE_and_Variance_with_rank.png\"), bbox_inches = \"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is the error temporarily distributed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [2, 5, 10, 25, 50, 100, 250, 300, 1000]\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (8, 3))\n",
    "timesteps = range(config.time_steps_per_cond)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for rank in ranks:\n",
    "    # Compute MSE for test dataset 1\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "    mse = ((X_test_1 - reconstructed)**2).mean(0)\n",
    "    ax1.plot(timesteps, mse, label=\"rank {}\".format(rank))\n",
    "\n",
    "# ax1.set_title(\"Test Dataset 1\")\n",
    "ax1.set_ylabel(\"MSE\")\n",
    "ax1.set_xlabel(\"timestep\")\n",
    "\n",
    "fig.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"temporal_MSE_distribution.png\"), bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the spatial error evolve for one specific timestep with inceasing rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates\n",
    "coords = pt.load(join(DATA_PATH, \"coords_interp.pt\"))\n",
    "x, y = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharey=True)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for i, rank in enumerate([5, 25, 250]):\n",
    "    # reduce and reconstruct dataset\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "\n",
    "    # compute the spatial MSE \n",
    "    mse1 = ((X_test_1 - reconstructed)**2).mean(1).unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "    # reduce and reconstruct dataset\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "\n",
    "    # compute the spatial MSE \n",
    "    mse2 = ((X_test_2 - reconstructed)**2).mean(1).unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "    # compute the mean MSE and the corresponding standard deviation for the lowest rank to compare to higher ranks\n",
    "    if i == 0:\n",
    "        mean, std = mse1.mean(), mse1.std()\n",
    "        vmin, vmax = 0, mean + 1*std\n",
    "        levels = pt.linspace(vmin, vmax, 120)\n",
    "\n",
    "        axes[0][i].set_ylabel(\"Test Dataset 1\")\n",
    "        axes[1][i].set_ylabel(\"Test Dataset 2\")\n",
    "\n",
    "    # create the contour plot\n",
    "    cont = axes[0][i].contourf(x, y, mse1, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "    cont = axes[1][i].contourf(x, y, mse2, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "\n",
    "    # formatting\n",
    "    axes[0][i].set_title(\"rank = {}\".format(rank))\n",
    "\n",
    "    for row in range(2):\n",
    "        axes[row][i].set_aspect(\"equal\")\n",
    "        axes[row][i].set_xticklabels([])\n",
    "        axes[row][i].set_yticklabels([])\n",
    "\n",
    "# add seperate subplot for color axis\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cax = fig.add_axes([0.99, 0.042, 0.03, 0.885])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"MSE\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"spatial_MSE_distribution.png\"), bbox_inches = \"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the reconstructed timestep look like for different ranks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharey=True)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for i, rank in enumerate([5, 250, \"experimental\"]):\n",
    "    \n",
    "    # create the contour plot\n",
    "    if rank == \"experimental\":\n",
    "        cont = axes[0][i].contourf(x, y, X_test_1[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES), vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        cont = axes[1][i].contourf(x, y, X_test_2[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES), vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        axes[0][i].set_title(\"Ground Truth\")\n",
    "    else:\n",
    "        # reduce and reconstruct dataset\n",
    "        reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1\n",
    "        reconstructed = U[:,:rank] @ reduced\n",
    "        reconstructed_timestep1 = reconstructed[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "        # reduce and reconstruct dataset\n",
    "        reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2\n",
    "        reconstructed = U[:,:rank] @ reduced\n",
    "        reconstructed_timestep2 = reconstructed[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "        # compute the mean MSE and the corresponding standard deviation for the lowest rank to compare to higher ranks\n",
    "        if i == 0:\n",
    "            mean, std = reconstructed_timestep1.mean(), reconstructed_timestep1.std()\n",
    "            vmin, vmax = mean - 2*std, mean + 2*std\n",
    "            levels = pt.linspace(vmin, vmax, 120)\n",
    "\n",
    "            axes[0][i].set_ylabel(\"Test Dataset 1\")\n",
    "            axes[1][i].set_ylabel(\"Test Dataset 2\")\n",
    "\n",
    "        cont = axes[0][i].contourf(x, y, reconstructed_timestep1, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        cont = axes[1][i].contourf(x, y, reconstructed_timestep2, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        axes[0][i].set_title(\"rank = {}\".format(rank))\n",
    "\n",
    "    for row in range(2):\n",
    "        axes[row][i].set_aspect(\"equal\")\n",
    "        axes[row][i].set_xticklabels([])\n",
    "        axes[row][i].set_yticklabels([])\n",
    "\n",
    "# add seperate subplot for color axis\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cax = fig.add_axes([0.99, 0.042, 0.03, 0.885])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = r\"$c_p$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"timestep_reconstruction.png\"), bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
