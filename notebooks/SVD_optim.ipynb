{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "import torch as pt\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker \n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# include app directory into sys.path\n",
    "parent_dir = os.path.abspath(join(os.getcwd(), os.pardir))\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "from utils import config\n",
    "\n",
    "# increase plot resolution\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# retrieve parameters from config\n",
    "TIMESTEP = config.timestep_reconstruction\n",
    "dimless_factor = config.U_inf / (config.c_mean * config.timesteps_per_second)\n",
    "TIMESTEP_dimless = round((TIMESTEP * dimless_factor),2)\n",
    "print(TIMESTEP_dimless)\n",
    "NEW_RES = config.target_resolution\n",
    "test_keys = config.test_keys_all\n",
    "\n",
    "# defined paths\n",
    "DATA_PATH = join(parent_dir, \"data\", \"SVD\")\n",
    "OUTPUT_PATH = join(parent_dir, \"output\", \"SVD\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load left singular vectors and temporal mean\n",
    "U = pt.load(join(OUTPUT_PATH, \"U.pt\"))\n",
    "mean = pt.load(join(OUTPUT_PATH, \"mean.pt\"))\n",
    "\n",
    "# Load test datsets\n",
    "X_test_1= pt.load(join(DATA_PATH, \"X_test_1.pt\"))                       # 3.00\n",
    "X_test_1_temp_mean = X_test_1.mean(dim=1).unsqueeze(-1)\n",
    "X_test_1_centered = X_test_1 - mean\n",
    "\n",
    "X_test_2 = pt.load(join(DATA_PATH, \"X_test_2.pt\"))                      # 5.00\n",
    "X_test_2_temp_mean = X_test_2.mean(dim=1).unsqueeze(-1)\n",
    "X_test_2_centered = X_test_2 - mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute MSE and R-squared for different ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to loop over an increasing number of left singular vectors\n",
    "ranks = range(1, 400, 5)\n",
    "\n",
    "# Initialize lists to save the computed metrics\n",
    "MSE_1 = []\n",
    "MSE_2 = []\n",
    "Var1 = []\n",
    "Var2 = []\n",
    "\n",
    "# compute the total variance of the test datasets\n",
    "orig_Var1 = pt.var(X_test_1)\n",
    "orig_Var2 = pt.var(X_test_2)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for i, rank in enumerate(ranks):\n",
    "    # Compute MSE for test dataset 1\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1_centered\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "    MSE_1.append(F.mse_loss(reconstructed + mean, X_test_1).item())\n",
    "\n",
    "    # Compute variance reconstruction for test dataset 1\n",
    "    Var1.append((1 - (MSE_1[i] / orig_Var1)))\n",
    "\n",
    "    # Compute MSE for test dataset 2\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2_centered\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "    MSE_2.append(F.mse_loss(reconstructed + mean, X_test_2).item())\n",
    "\n",
    "    # Compute variance reconstruction for test dataset 2\n",
    "    Var2.append((1 - (MSE_2[i] / orig_Var2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results and save the figure\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax1.plot(ranks, MSE_1, label=\"Test Dataset 1\")\n",
    "ax1.plot(ranks, MSE_2, label=\"Test Dataset 2\")\n",
    "ax1.set_title(\"MSE\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_ylim(config.plot_lims_MSE_general)\n",
    "\n",
    "ax2.plot(ranks, Var1, label=\"Test Dataset 1\")\n",
    "ax2.plot(ranks, Var2, label=\"Test Dataset 2\")\n",
    "ax2.set_title(rf\"Variance Reconstruction (RÂ²)\")\n",
    "ax2.set_xlabel(\"rank\")\n",
    "ax2.set_ylim(config.plot_lims_R_squarred)\n",
    "ax2.set_xticks(range(0, 401, 50))\n",
    "\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels)\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"SVD_MSE_and_Rsquarred_with_rank.png\"), bbox_inches = \"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute temporal MSE distribution for different ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrarily chosen ranks\n",
    "ranks = [1, 3, 10, 30, 100, 300, 500, 1000]\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (8, 3))\n",
    "\n",
    "# compute dimensionless time\n",
    "timesteps = [(t * dimless_factor) for t in range(config.time_steps_per_cond)]\n",
    "\n",
    "# Loop over the U ranks\n",
    "for rank in ranks:\n",
    "    # Compute MSE for test dataset 1\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1_centered\n",
    "    reconstructed = (U[:,:rank] @ reduced) + mean\n",
    "    mse = ((X_test_1 - reconstructed )**2).mean(0)\n",
    "    ax1.plot(timesteps, mse, label=\"rank {}\".format(rank))\n",
    "\n",
    "# ax1.set_title(\"Test Dataset 1\")\n",
    "ax1.set_ylabel(\"MSE\")\n",
    "ax1.set_xlabel(rf\"$\\tau$\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_ylim(config.plot_lims_MSE_temporal)\n",
    "\n",
    "fig.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"SVD_temporal_MSE_distribution.png\"), bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute spatial MSE distribution for different ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates\n",
    "coords = pt.load(join(Path(DATA_PATH).parent, \"coords_interp.pt\"))\n",
    "x, y = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharey=True)\n",
    "vmin, vmax = config.plot_lims_MSE_reconstruction\n",
    "levels = pt.linspace(vmin, vmax, 120)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for i, rank in enumerate([3, 30, 300]):\n",
    "    # reduce and reconstruct dataset\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1_centered\n",
    "    reconstructed = (U[:,:rank] @ reduced)  + mean\n",
    "\n",
    "    # compute the spatial MSE \n",
    "    mse1 = ((X_test_1 - reconstructed)**2).mean(1).unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "    # reduce and reconstruct dataset\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2_centered\n",
    "    reconstructed = U[:,:rank] @ reduced + mean\n",
    "\n",
    "    # compute the spatial MSE \n",
    "    mse2 = ((X_test_2 - reconstructed)**2).mean(1).unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "    # create the contour plot\n",
    "    cont = axes[0][i].contourf(x, y, mse1, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "    cont = axes[1][i].contourf(x, y, mse2, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "\n",
    "    # formatting\n",
    "    axes[0][i].set_title(\"rank = {}\".format(rank))\n",
    "\n",
    "    for row in range(2):\n",
    "        axes[row][i].set_aspect(\"equal\")\n",
    "        axes[row][i].set_xticklabels([])\n",
    "        axes[row][i].set_yticklabels([])\n",
    "\n",
    "axes[0][0].set_ylabel(\"Test Dataset 1\")\n",
    "axes[1][0].set_ylabel(\"Test Dataset 2\")\n",
    "\n",
    "# add seperate subplot for color axis\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cax = fig.add_axes([0.99, 0.042, 0.03, 0.885])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"MSE\")\n",
    "cbar.formatter = ticker.FormatStrFormatter(f'%.{3}f')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"SVD_spatial_MSE_distribution.png\"), bbox_inches = \"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct $c_p$-snapshot for different ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharey=True)\n",
    "vmin, vmax = config.plot_lims_cp\n",
    "levels = pt.linspace(vmin, vmax, 120)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for i, rank in enumerate([30, 300, \"experimental\"]):\n",
    "    \n",
    "    # create the contour plot\n",
    "    if rank == \"experimental\":\n",
    "        cont = axes[0][i].contourf(x, y, X_test_1[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES), vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        cont = axes[1][i].contourf(x, y, X_test_2[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES), vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        axes[0][i].set_title(\"Ground Truth\")\n",
    "    else:\n",
    "        # reduce and reconstruct dataset 1\n",
    "        reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1_centered\n",
    "        reconstructed = (U[:,:rank] @ reduced)  + mean\n",
    "        reconstructed_timestep1 = reconstructed[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "        # reduce and reconstruct dataset 2\n",
    "        reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2_centered\n",
    "        reconstructed = (U[:,:rank] @ reduced) + mean\n",
    "        reconstructed_timestep2 = reconstructed[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "        cont = axes[0][i].contourf(x, y, reconstructed_timestep1, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        cont = axes[1][i].contourf(x, y, reconstructed_timestep2, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        axes[0][i].set_title(\"rank = {}\".format(rank))\n",
    "\n",
    "    for row in range(2):\n",
    "        axes[row][i].set_aspect(\"equal\")\n",
    "        axes[row][i].set_xticklabels([])\n",
    "        axes[row][i].set_yticklabels([])\n",
    "\n",
    "axes[0][0].set_ylabel(\"Test Dataset 1\")\n",
    "axes[1][0].set_ylabel(\"Test Dataset 2\")\n",
    "\n",
    "# add seperate subplot for color axis\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cax = fig.add_axes([0.99, 0.042, 0.03, 0.885])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = r\"Normalized $c_p$\")\n",
    "cbar.formatter = ticker.FormatStrFormatter(f'%.{2}f')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"SVD_timestep_reconstruction.png\"), bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
