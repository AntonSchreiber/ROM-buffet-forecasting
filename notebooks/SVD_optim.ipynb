{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition (SVD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.c: evaluate the reconstruction performance on at least two IPSP datasets that were not part of the training\n",
    "\n",
    "1. Load test data sets and U, subtract temporal mean from test datasets\n",
    "3. Transform the test data into the reduced state with $$ X_{test,reduced} = U_{reduced}^T X_{test} $$\n",
    "4. Reconstruct the reduced test data $ X_{test,reduced} $ with $$ X_{test,reconstr} = U_{reduced} X_{test,reduced}$$\n",
    "5. Compare the reconstructed test set with the original test set using MSE and variance reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "# include app directory into sys.path\n",
    "parent_dir = os.path.abspath(join(os.getcwd(), os.pardir))\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "import torch as pt\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import utils.config as config\n",
    "from importlib import reload\n",
    "reload(config)\n",
    "\n",
    "random.seed(10)\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "DATA_PATH = join(parent_dir, \"data\", \"SVD\")\n",
    "OUTPUT_PATH = join(parent_dir, \"output\", \"SVD\")\n",
    "\n",
    "TIMESTEP = config.timestep_reconstruction\n",
    "TIMESTEP_dimless = (TIMESTEP * config.U_inf) / (config.c_mean * config.timesteps_per_second)\n",
    "print(TIMESTEP_dimless)\n",
    "NEW_RES = config.target_resolution\n",
    "\n",
    "test_keys = config.test_keys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load test datasets and U, subtract temporal mean from test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test datsets\n",
    "X_test_1= pt.load(join(DATA_PATH, \"X_test_1.pt\"))                       # 3.00\n",
    "X_test_1_temp_mean = X_test_1.mean(dim=1).unsqueeze(-1)\n",
    "X_test_1_centered = X_test_1 - X_test_1_temp_mean\n",
    "print(\"Min-Max of uncentered Test 1:        \", X_test_1.max(), X_test_1.min())\n",
    "print(\"Min-Max of centered Test 1:          \", X_test_1_centered.max(), X_test_1_centered.min())\n",
    "print(\"Var of uncentered Test 1:            \", pt.var(X_test_1))\n",
    "print(\"Var of centered Test 1:              \", pt.var(X_test_1_centered))\n",
    "\n",
    "X_test_2 = pt.load(join(DATA_PATH, \"X_test_2.pt\"))                      # 5.00\n",
    "X_test_2_temp_mean = X_test_2.mean(dim=1).unsqueeze(-1)\n",
    "X_test_2_centered = X_test_2 - X_test_2_temp_mean\n",
    "\n",
    "# Load left singular vectors\n",
    "U = pt.load(join(OUTPUT_PATH, \"U.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - 4 Reduce-Reconstruct datasets and compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to loop over an increasing number of left singular vectors\n",
    "ranks = range(1, 400, 5)\n",
    "\n",
    "# Initialize lists to save the computed metrics\n",
    "MSE_1 = []\n",
    "MSE_2 = []\n",
    "Var1 = []\n",
    "Var2 = []\n",
    "\n",
    "# compute the total variance of the test datasets\n",
    "orig_Var1 = pt.var(X_test_1)\n",
    "orig_Var2 = pt.var(X_test_2)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for i, rank in enumerate(ranks):\n",
    "    # Compute MSE for test dataset 1\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1_centered\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "    MSE_1.append(F.mse_loss(reconstructed + X_test_1_temp_mean, X_test_1).item())\n",
    "\n",
    "    # Compute variance reconstruction for test dataset 1\n",
    "    Var1.append((1 - (MSE_1[i] / orig_Var1)))\n",
    "\n",
    "    # Compute MSE for test dataset 2\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2_centered\n",
    "    reconstructed = U[:,:rank] @ reduced\n",
    "    MSE_2.append(F.mse_loss(reconstructed + X_test_2_temp_mean, X_test_2).item())\n",
    "\n",
    "    # Compute variance reconstruction for test dataset 2\n",
    "    Var2.append((1 - (MSE_2[i] / orig_Var2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results and save the figure\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax1.plot(ranks, MSE_1, label=\"Test Dataset 1\")\n",
    "ax1.plot(ranks, MSE_2, label=\"Test Dataset 2\")\n",
    "ax1.set_title(\"MSE\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_ylim(config.plot_lims_MSE_general)\n",
    "\n",
    "ax2.plot(ranks, Var1, label=\"Test Dataset 1\")\n",
    "ax2.plot(ranks, Var2, label=\"Test Dataset 2\")\n",
    "ax2.set_title(rf\"Variance Reconstruction (RÂ²)\")\n",
    "ax2.set_xlabel(\"rank\")\n",
    "ax2.set_ylim(config.plot_lims_R_squarred)\n",
    "ax2.set_xticks(range(0, 401, 50))\n",
    "\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels)\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"SVD_MSE_and_Rsquarred_with_rank.png\"), bbox_inches = \"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is the error temporarily distributed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [1, 3, 10, 30, 100, 300, 500, 1000]\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (8, 3))\n",
    "timesteps = [(t * config.U_inf) / (config.c_mean * config.timesteps_per_second) for t in range(config.time_steps_per_cond)]\n",
    "\n",
    "# Loop over the U ranks\n",
    "for rank in ranks:\n",
    "    # Compute MSE for test dataset 1\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1_centered\n",
    "    reconstructed = (U[:,:rank] @ reduced) + X_test_1_temp_mean\n",
    "    mse = ((X_test_1 - reconstructed )**2).mean(0)\n",
    "    ax1.plot(timesteps, mse, label=\"rank {}\".format(rank))\n",
    "\n",
    "# ax1.set_title(\"Test Dataset 1\")\n",
    "ax1.set_ylabel(\"MSE\")\n",
    "ax1.set_xlabel(rf\"$\\tau$\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_ylim(config.plot_lims_MSE_temporal)\n",
    "\n",
    "fig.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"SVD_temporal_MSE_distribution.png\"), bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the spatial error evolve for one specific timestep with inceasing rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates\n",
    "coords = pt.load(join(Path(DATA_PATH).parent, \"coords_interp.pt\"))\n",
    "x, y = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharey=True)\n",
    "vmin, vmax = config.plot_lims_MSE_spatial\n",
    "levels = pt.linspace(vmin, vmax, 120)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for i, rank in enumerate([3, 30, 300]):\n",
    "    # reduce and reconstruct dataset\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1_centered\n",
    "    reconstructed = (U[:,:rank] @ reduced)  + X_test_1_temp_mean\n",
    "\n",
    "    # compute the spatial MSE \n",
    "    mse1 = ((X_test_1 - reconstructed)**2).mean(1).unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "    # reduce and reconstruct dataset\n",
    "    reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2_centered\n",
    "    reconstructed = U[:,:rank] @ reduced + X_test_2_temp_mean\n",
    "\n",
    "    # compute the spatial MSE \n",
    "    mse2 = ((X_test_2 - reconstructed)**2).mean(1).unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "    # create the contour plot\n",
    "    cont = axes[0][i].contourf(x, y, mse1, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "    cont = axes[1][i].contourf(x, y, mse2, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "\n",
    "    # formatting\n",
    "    axes[0][i].set_title(\"rank = {}\".format(rank))\n",
    "\n",
    "    for row in range(2):\n",
    "        axes[row][i].set_aspect(\"equal\")\n",
    "        axes[row][i].set_xticklabels([])\n",
    "        axes[row][i].set_yticklabels([])\n",
    "\n",
    "axes[0][0].set_ylabel(\"Test Dataset 1\")\n",
    "axes[1][0].set_ylabel(\"Test Dataset 2\")\n",
    "\n",
    "# add seperate subplot for color axis\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cax = fig.add_axes([0.99, 0.042, 0.03, 0.885])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"MSE\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"SVD_spatial_MSE_distribution.png\"), bbox_inches = \"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the reconstructed timestep look like for different ranks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharey=True)\n",
    "vmin, vmax = config.plot_lims_cp\n",
    "levels = pt.linspace(vmin, vmax, 120)\n",
    "\n",
    "# Loop over the U ranks\n",
    "for i, rank in enumerate([30, 300, \"experimental\"]):\n",
    "    \n",
    "    # create the contour plot\n",
    "    if rank == \"experimental\":\n",
    "        cont = axes[0][i].contourf(x, y, X_test_1[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES), vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        cont = axes[1][i].contourf(x, y, X_test_2[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES), vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        axes[0][i].set_title(\"Ground Truth\")\n",
    "    else:\n",
    "        # reduce and reconstruct dataset\n",
    "        reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_1_centered\n",
    "        reconstructed = (U[:,:rank] @ reduced)  + X_test_1_temp_mean\n",
    "        reconstructed_timestep1 = reconstructed[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "        # reduce and reconstruct dataset\n",
    "        reduced = pt.transpose(U[:,:rank], 0, 1) @ X_test_2_centered\n",
    "        reconstructed = (U[:,:rank] @ reduced)  + X_test_2_temp_mean\n",
    "        reconstructed_timestep2 = reconstructed[:, TIMESTEP].unflatten(dim=0, sizes=NEW_RES)\n",
    "\n",
    "        cont = axes[0][i].contourf(x, y, reconstructed_timestep1, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        cont = axes[1][i].contourf(x, y, reconstructed_timestep2, vmin=vmin, vmax=vmax, levels=levels, extend=\"both\")\n",
    "        axes[0][i].set_title(\"rank = {}\".format(rank))\n",
    "\n",
    "    for row in range(2):\n",
    "        axes[row][i].set_aspect(\"equal\")\n",
    "        axes[row][i].set_xticklabels([])\n",
    "        axes[row][i].set_yticklabels([])\n",
    "\n",
    "axes[0][0].set_ylabel(\"Test Dataset 1\")\n",
    "axes[1][0].set_ylabel(\"Test Dataset 2\")\n",
    "\n",
    "# add seperate subplot for color axis\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cax = fig.add_axes([0.99, 0.042, 0.03, 0.885])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = r\"$c_p$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"SVD_timestep_reconstruction.png\"), bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
