{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# include app directory into sys.path\n",
    "parent_dir = Path(os.path.abspath('')).parent\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "import torch as pt\n",
    "from torch.nn.functional import mse_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "import utils.config as config\n",
    "from utils.helper_funcs import find_target_index_in_dataset\n",
    "from CNN_VAE.CNN_VAE import make_VAE_model\n",
    "from FC.FullyConnected import make_FC_model\n",
    "from utils.helper_funcs import shift_input_sequence\n",
    "from utils.DataWindow import DataWindow\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# use GPU if possible\n",
    "device = pt.device(\"cuda\") if pt.cuda.is_available() else pt.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# define prediction horizon and type of dimensionality reduction\n",
    "PRED_HORIZON = 2\n",
    "DIM_REDUCTION = \"VAE\"       # one of (\"SVD\" / \"VAE\")\n",
    "N_LATENT = config.SVD_rank if DIM_REDUCTION == \"SVD\" else config.VAE_latent_size\n",
    "\n",
    "# define paths\n",
    "DATA_PATH = join(parent_dir, \"data\", \"single_flow_cond\")\n",
    "VAE_PATH = join(parent_dir, \"output\", \"VAE\", \"latent_study\", config.VAE_model)\n",
    "SVD_PATH = join(parent_dir, \"output\", \"SVD\", \"U.pt\")\n",
    "FC_MODEL = \"32_256_1\"\n",
    "FC_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\", f\"pred_horizon_{PRED_HORIZON}\")\n",
    "OUTPUT_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Parameter Study Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load study results\n",
    "study_results = pt.load(join(FC_PATH, \"study_results.pt\"))\n",
    "param_combinations = list(study_results.keys())\n",
    "\n",
    "# find parameter combinations of study and extract test loss\n",
    "hidden_size = np.unique([int(param_set.split('_')[1]) for param_set in param_combinations])\n",
    "n_hidden = np.unique([int(param_set.split('_')[2]) for param_set in param_combinations])\n",
    "test_losses = np.array([study_results[param_set][0][\"val_loss\"].values[-10:].mean() for param_set in param_combinations])\n",
    "\n",
    "X, Y = np.meshgrid(hidden_size, n_hidden)\n",
    "\n",
    "# Sort the indexed losses based on the values (ascending order)\n",
    "sorted_losses = sorted(list(enumerate(test_losses)), key=lambda x: x[1])\n",
    "lowest_loss_idx = [index for index, _ in sorted_losses[:5]]\n",
    "\n",
    "print(\"The param combinations with the lowest loss: [input_width, hidden_size, n_hidden]\")\n",
    "print([param_combinations[i] for i in lowest_loss_idx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "heatmap = plt.pcolormesh(X, Y, test_losses.reshape(X.shape), cmap='viridis')\n",
    "\n",
    "plt.colorbar(heatmap, label='Test Loss')\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Hidden Layer Neurons')\n",
    "plt.title('Parameter Study: Test Loss Heatmap')\n",
    "plt.xticks(hidden_size)\n",
    "plt.yticks(n_hidden)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have larger values at the top\n",
    "plt.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_param_study.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestep computation (test datasat comprises two flow conditions, 500 timesteps each)\n",
    "TIMESTEP = config.timestep_prediction_single    \n",
    "print(f\"Test dataset comprises timesteps {int(config.single_flow_cond_train_share * config.time_steps_per_cond)} - {config.time_steps_per_cond}\")     \n",
    "print(f\"Predicted timestep is {TIMESTEP}\")\n",
    "TIMESTEP = int(TIMESTEP - config.time_steps_per_cond * config.single_flow_cond_train_share) # to receive index of test data subtract number of samples in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE(train, test):\n",
    "    # load pre-trained autoencoder model\n",
    "    autoencoder = make_VAE_model(\n",
    "        n_latent=config.VAE_latent_size, \n",
    "        device=device)\n",
    "    autoencoder.load(VAE_PATH)\n",
    "    autoencoder.eval()\n",
    "    decoder = autoencoder._decoder\n",
    "\n",
    "    # encode datasets\n",
    "    train_red = autoencoder.encode_dataset(train)\n",
    "    test_red = autoencoder.encode_dataset(test)\n",
    "    return train_red, test_red, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experimental data\n",
    "train_data_orig = pt.load(join(DATA_PATH, f\"{DIM_REDUCTION}_test.pt\"))\n",
    "test_data_orig = pt.load(join(DATA_PATH, f\"{DIM_REDUCTION}_test.pt\"))\n",
    "\n",
    "# load coordinate grids\n",
    "coords = pt.load(join(Path(DATA_PATH).parent, \"coords_interp.pt\"))\n",
    "xx, yy = coords\n",
    "\n",
    "# load pre-fitted scaler\n",
    "latent_scaler = pt.load(join(OUTPUT_PATH, \"scaler.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress dataset into reduced state either by VAE or SVD\n",
    "if DIM_REDUCTION == \"VAE\":\n",
    "    train_red, test_red, decoder = VAE(train_data_orig, test_data_orig)\n",
    "elif DIM_REDUCTION == \"SVD\":\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(\"Unknown DIM_REDUCTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed reduced and scaled dataset into DataWindow class to create TimeSeriesTensorDatasets\n",
    "data_window = DataWindow(train=latent_scaler.scale(train_red), test=latent_scaler.scale(test_red), input_width=INPUT_WIDTH, pred_horizon=PRED_HORIZON)\n",
    "_, target_idx = data_window.rolling_window(test_red.shape[1])\n",
    "target_idx = target_idx.tolist()\n",
    "\n",
    "test_windows = data_window.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define FC model parameters\n",
    "INPUT_WIDTH, HIDDEN_SIZE, N_HIDDEN_LAYERS = [int(param) for param in FC_MODEL.split(\"_\")]\n",
    "\n",
    "# create FC model and load model state dict\n",
    "FC_model = make_FC_model(\n",
    "    latent_size=N_LATENT,\n",
    "    input_width=INPUT_WIDTH, \n",
    "    hidden_size=HIDDEN_SIZE, \n",
    "    n_hidden_layers=N_HIDDEN_LAYERS\n",
    ")\n",
    "FC_model.load(join(FC_PATH, FC_MODEL + \".pt\"))\n",
    "FC_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize losses\n",
    "latent_loss = []\n",
    "orig_loss = []\n",
    "\n",
    "# find index of input-target pair in test dataset that predicts TIMESTEP\n",
    "timestep_id = find_target_index_in_dataset(nested_list=target_idx, target_id=TIMESTEP)\n",
    "print(target_idx)\n",
    "print(timestep_id)\n",
    "\n",
    "with pt.no_grad():\n",
    "    inputs, targets = test_windows[timestep_id]\n",
    "    # add batch dimension with unsqueeze(0)\n",
    "    inputs = inputs.flatten().unsqueeze(0).to(device)\n",
    "    targets = targets.unsqueeze(0).to(device)\n",
    "\n",
    "    for step in range(PRED_HORIZON):\n",
    "        # shift input sequence by one: add last prediction while discarding first input\n",
    "        if step != 0:\n",
    "            inputs = shift_input_sequence(orig_seq=inputs, new_pred=pred)\n",
    "\n",
    "        # time-evolution (autoregressive)\n",
    "        pred = FC_model(inputs)\n",
    "        latent_loss.append(mse_loss(targets[:, :, step], pred))\n",
    "\n",
    "        # re-scaling\n",
    "        pred_rescaled = latent_scaler.rescale(pred)\n",
    "\n",
    "        # expand to full space either by VAE or SVD\n",
    "        if DIM_REDUCTION == \"VAE\":\n",
    "            # forward pass through decoder\n",
    "            pred_orig = decoder(pred_rescaled.unsqueeze(0)).squeeze().detach() \n",
    "        else:\n",
    "            # matrix multiplication with U, followed by adding back the temporal mean\n",
    "            pred_orig = (U @ pred_rescaled.permute(1, 0) + test_data_orig.flatten(0, 1).mean(dim=1).unsqueeze(-1)).squeeze().unflatten(dim=0, sizes=config.target_resolution)\n",
    "        \n",
    "        print(pred_orig.shape)\n",
    "\n",
    "        orig_loss.append(mse_loss(test_data_orig[:, :, target_idx[timestep_id][step]], pred_orig))\n",
    "\n",
    "MSE = (test_data_orig[:, :, TIMESTEP] - pred_orig)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Latent vs. Full Space Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(1, 1, figsize=config.standard_figsize_1)\n",
    "plt.plot(range(1, PRED_HORIZON + 1), latent_loss, label=\"reduced space loss\")\n",
    "plt.plot(range(1, PRED_HORIZON + 1), orig_loss, label=\"full space loss\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"number of autoregressive predictions\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_origvslatentloss.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Original vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "vmin_cp, vmax_cp = config.plot_lims_cp\n",
    "vmin_MSE, vmax_MSE = config.plot_lims_MSE_reconstruction\n",
    "levels_cp = pt.linspace(vmin_cp, vmax_cp, 120)\n",
    "levels_MSE = pt.linspace(vmin_MSE, vmax_MSE, 120)\n",
    "\n",
    "ax1.contourf(xx, yy, test_data_orig[:, :, TIMESTEP], vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "ax2.contourf(xx, yy, pred_orig, vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "cont = ax3.contourf(xx, yy, MSE, vmin=vmin_MSE, vmax=vmax_MSE, levels=levels_MSE)\n",
    "\n",
    "ax1.set_title(\"Ground Truth\")\n",
    "ax2.set_title(DIM_REDUCTION + \"-FC\")\n",
    "\n",
    "fig.subplots_adjust(right=0.95)\n",
    "cax = fig.add_axes([0.99, 0.283, 0.03, 0.424])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"Squarred Error\")\n",
    "cbar.formatter = ticker.FormatStrFormatter(f'%.{2}f')\n",
    "\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_timestep_reconstr.png\"), bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
