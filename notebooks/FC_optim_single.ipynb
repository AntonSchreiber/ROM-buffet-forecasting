{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# include app directory into sys.path\n",
    "parent_dir = Path(os.path.abspath('')).parent\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "import torch as pt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import numpy as np\n",
    "\n",
    "import utils.config as config\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# define prediction horizon and type of dimensionality reduction\n",
    "PRED_HORIZON = 64\n",
    "DIM_REDUCTION = \"SVD\"       # one of (\"SVD\" / \"VAE\")\n",
    "\n",
    "# define paths\n",
    "FC_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\", f\"pred_horizon_{PRED_HORIZON}\")\n",
    "OUTPUT_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Study Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load study results\n",
    "study_results = pt.load(join(FC_PATH, \"study_results.pt\"))\n",
    "param_combinations = list(study_results.keys())\n",
    "\n",
    "# find parameter combinations of study and extract test loss\n",
    "hidden_size = np.unique([int(param_set.split('_')[1]) for param_set in param_combinations])\n",
    "n_hidden = np.unique([int(param_set.split('_')[2]) for param_set in param_combinations])\n",
    "\n",
    "X, Y = np.meshgrid(hidden_size, n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of test loss for each epoch for each parameter combination\n",
    "train_means = {}\n",
    "test_means = {}\n",
    "\n",
    "for param_combination in study_results:\n",
    "    all_test_losses = []\n",
    "    all_train_losses = []\n",
    "    for df in study_results[param_combination]:\n",
    "        all_test_losses.append(df[\"val_loss\"])\n",
    "        all_train_losses.append(df[\"train_loss\"])\n",
    "    \n",
    "    # Pad shorter training sequences with NaNs to ensure equal lengths\n",
    "    all_test_losses_padded = np.array([np.pad(loss, (0, 500 - len(loss)), mode='constant', constant_values=np.nan) for loss in all_test_losses])\n",
    "    all_train_losses_padded = np.array([np.pad(loss,(0, 500 - len(loss)), mode='constant', constant_values=np.nan) for loss in all_train_losses])\n",
    "    \n",
    "    # Calculate mean and std while ignoring NaN values\n",
    "    test_means[param_combination] = np.nanmean(all_test_losses_padded, axis=0)\n",
    "    train_means[param_combination] = np.nanmean(all_train_losses_padded, axis=0)\n",
    "\n",
    "# Create the plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 3), sharey = True, sharex = True)\n",
    "\n",
    "# Plot mean test loss with 2 sigma confidence interval for each latent size\n",
    "for size in study_results:\n",
    "    ax1.plot(np.arange(1, config.VAE_epochs + 1), train_means[size], label=f'Latent Size {size}')\n",
    "    ax2.plot(np.arange(1, config.VAE_epochs + 1), test_means[size], label=f'Latent Size {size}')\n",
    "\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_title(\"Train MSE Mean\")\n",
    "ax2.set_xlabel(\"epoch\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_title(\"Test MSE Mean\")\n",
    "ax1.legend(loc=1, bbox_to_anchor=(1,1))\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "plt.xlim(0, config.VAE_epochs)\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_loss_mean.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_mean = np.array([test_means[param_comb][-10:].mean() for param_comb in test_means.keys()])\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=config.standard_figsize_2)\n",
    "heatmap = plt.pcolormesh(X, Y, final_test_mean.reshape(X.shape), cmap='viridis', norm=LogNorm())\n",
    "\n",
    "plt.colorbar(heatmap, label='Test Loss')\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Hidden Layer Neurons')\n",
    "plt.title('Parameter Study: Test Loss Heatmap')\n",
    "plt.xticks(hidden_size)\n",
    "plt.yticks(n_hidden)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have larger values at the top\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_param_study.png\"), bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
