{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CNN-VAE (reduction) with Fully-Connected Net (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# include app directory into sys.path\n",
    "parent_dir = Path(os.path.abspath('')).parent\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "import torch as pt\n",
    "from torch.nn.functional import mse_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import utils.config as config\n",
    "from utils.helper_funcs import find_target_index_in_dataset\n",
    "from utils.CNN_VAE import make_VAE_model\n",
    "from utils.FullyConnected import make_FC_model\n",
    "from utils.helper_funcs import shift_input_sequence\n",
    "from utils.DataWindow import DataWindow\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# use GPU if possible\n",
    "device = pt.device(\"cuda\") if pt.cuda.is_available() else pt.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "DATA_PATH = join(parent_dir, \"data\", \"single_flow_cond\")\n",
    "VAE_PATH = join(parent_dir, \"output\", \"VAE\", \"latent_study\", config.VAE_model)\n",
    "FC_MODEL = \"40_256_1\"\n",
    "FC_PATH = join(parent_dir, \"output\", \"VAE_FC\", \"param_study\", \"pred_horizon_6\")\n",
    "LATENT_SIZE = config.VAE_latent_size\n",
    "OUTPUT_PATH = join(parent_dir, \"output\", \"VAE_FC\", \"param_study\")\n",
    "\n",
    "PRED_HORIZON = 6\n",
    "TIMESTEP = config.timestep_reconstruction_single\n",
    "TIMESTEP_dimless = (TIMESTEP * config.U_inf) / (config.c_mean * config.timesteps_per_second)\n",
    "TIMESTEP = int(TIMESTEP - config.time_steps_per_cond * config.single_flow_cond_train_share) # to receive index of test data subtract number of samples in train data\n",
    "print(TIMESTEP_dimless)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data (single flow condition at alpha = 4.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "train = pt.load(join(DATA_PATH, \"VAE_train.pt\"))\n",
    "test = pt.load(join(DATA_PATH, \"VAE_test.pt\"))\n",
    "print(train.max(), train.min())\n",
    "print(test.max(), test.min())\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "coords = pt.load(join(Path(DATA_PATH).parent, \"coords_interp.pt\"))\n",
    "xx, yy = coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load autoencoder and encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained autoencoder model\n",
    "autoencoder = make_VAE_model(\n",
    "    n_latent=LATENT_SIZE, \n",
    "    device=device)\n",
    "autoencoder.load(VAE_PATH)\n",
    "autoencoder.eval()\n",
    "decoder = autoencoder._decoder\n",
    "\n",
    "# encode datasets\n",
    "train_enc = autoencoder.encode_dataset(train)\n",
    "test_enc = autoencoder.encode_dataset(test)\n",
    "print(test_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Fully-Connected Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results from parameter study\n",
    "INPUT_WIDTH = 40\n",
    "HIDDEN_SIZE = 256\n",
    "N_HIDDEN_LAYERS = 1\n",
    "\n",
    "FC_model = make_FC_model(\n",
    "    latent_size=LATENT_SIZE,\n",
    "    input_width=INPUT_WIDTH, \n",
    "    hidden_size=HIDDEN_SIZE, \n",
    "    n_hidden_layers=N_HIDDEN_LAYERS\n",
    ")\n",
    "FC_model.load(join(FC_PATH, FC_MODEL + \".pt\"))\n",
    "FC_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data, create Data Window and load into Time-Series TensorDataset to create input-target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_scaler = pt.load(join(FC_PATH, \"scaler.pt\"))\n",
    "data_window = DataWindow(train=latent_scaler.scale(train_enc), test=latent_scaler.scale(test_enc), input_width=INPUT_WIDTH, pred_horizon=PRED_HORIZON)\n",
    "_, target_idx = data_window.rolling_window(test_enc.shape[1])\n",
    "target_idx = target_idx.tolist()\n",
    "test_enc = data_window.test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute autoregressive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize losses\n",
    "latent_loss = []\n",
    "orig_loss = []\n",
    "\n",
    "# find index of input-target pair in test_enc that predicts TIMESTEP\n",
    "dataset_id = find_target_index_in_dataset(nested_list=target_idx, target_id=TIMESTEP)\n",
    "\n",
    "with pt.no_grad():\n",
    "    inputs, targets = test_enc[dataset_id]\n",
    "    # add batch dimension with unsqueeze(0)\n",
    "    inputs = inputs.flatten().unsqueeze(0).to(device)\n",
    "    targets = targets.unsqueeze(0).to(device)\n",
    "\n",
    "    for step in range(PRED_HORIZON):\n",
    "        # shift input sequence by one: add last prediction while discarding first input\n",
    "        if step != 0:\n",
    "            inputs = shift_input_sequence(orig_seq=inputs, new_pred=pred)\n",
    "\n",
    "        # time-evolution (autoregressive)\n",
    "        pred = FC_model(inputs)\n",
    "        latent_loss.append(mse_loss(targets[:, :, 0], pred))\n",
    "\n",
    "        # re-scaling\n",
    "        pred_rescaled = latent_scaler.rescale(pred)\n",
    "\n",
    "        # decoding to full space\n",
    "        pred_orig = decoder(pred_rescaled.unsqueeze(0)).squeeze().detach()\n",
    "        orig_loss.append(mse_loss(test[:, :, target_idx[dataset_id][step]], pred_orig))\n",
    "\n",
    "MSE = (test[:, :, TIMESTEP] - pred_orig)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Latent vs Original loss over the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(1, 1, figsize=config.standard_figsize_1)\n",
    "plt.plot(range(1, PRED_HORIZON + 1), latent_loss, label=\"Latent Loss\")\n",
    "plt.plot(range(1, PRED_HORIZON + 1), orig_loss, label=\"Orig Loss\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"number of autoregressive predictions\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.savefig(join(Path(FC_PATH).parent, \"VAE_FC_predhor2_origvslatentloss.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Original vs predicted Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "vmin_cp, vmax_cp = config.plot_lims_cp\n",
    "vmin_MSE, vmax_MSE = config.plot_lims_MSE_reconstruction\n",
    "levels_cp = pt.linspace(vmin_cp, vmax_cp, 120)\n",
    "levels_MSE = pt.linspace(vmin_MSE, vmax_MSE, 120)\n",
    "\n",
    "ax1.contourf(xx, yy, test[:, :, TIMESTEP], vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "ax2.contourf(xx, yy, pred_orig, vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "cont = ax3.contourf(xx, yy, MSE, vmin=vmin_MSE, vmax=vmax_MSE, levels=levels_MSE)\n",
    "\n",
    "ax1.set_title(\"Ground Truth\")\n",
    "ax2.set_title(\"CNN-VAE-FC\")\n",
    "\n",
    "fig.subplots_adjust(right=0.95)\n",
    "cax = fig.add_axes([0.99, 0.283, 0.03, 0.424])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"Squarred Error\")\n",
    "cbar.formatter = ticker.FormatStrFormatter(f'%.{2}f')\n",
    "\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "fig.savefig(join(Path(FC_PATH).parent, \"VAE_FC_predhor2_timestep_reconstr.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss vs. Prediction Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how the loss of the selected model configuration changes when the prediction horizon increases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
