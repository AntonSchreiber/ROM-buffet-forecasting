{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Variational Autoencoder (CNN-VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "parent_dir = os.path.abspath(join(os.getcwd(), os.pardir))\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "from pathlib import Path\n",
    "import torch as pt\n",
    "from CNN_VAE import ConvDecoder, ConvEncoder, Autoencoder\n",
    "import utils.config as config\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# use GPU if possible\n",
    "device = pt.device(\"cuda:0\") if pt.cuda.is_available() else pt.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "DATA_PATH = Path(os.path.abspath('')).parent / \"data\"\n",
    "OUTPUT_PATH = Path(os.path.abspath('')).parent / \"output\" / \"VAE\" /\"parameter_study\"\n",
    "\n",
    "test_case_name = \"256_batchnorm_lr1e-4_Plateau_f0.8nosquash\"\n",
    "\n",
    "latent_size = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Autoencoder and additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create VAE model\n",
    "def make_VAE_model(n_latent: int = 256) -> pt.nn.Module:\n",
    "    encoder = ConvEncoder(\n",
    "        in_size=config.target_resolution,\n",
    "        n_channels=config.input_channels,\n",
    "        n_latent=n_latent,\n",
    "        variational=True,\n",
    "        layernorm=True\n",
    "    )\n",
    "\n",
    "    decoder = ConvDecoder(\n",
    "        in_size=config.target_resolution,\n",
    "        n_channels=config.output_channels,\n",
    "        n_latent=n_latent,\n",
    "        layernorm=True,\n",
    "        squash_output=True\n",
    "    )\n",
    "\n",
    "    autoencoder = Autoencoder(encoder, decoder)\n",
    "    autoencoder.to(device)\n",
    "    return autoencoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets and initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pt.load(join(DATA_PATH, \"test_dataset.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "autoencoder = make_VAE_model(latent_size)\n",
    "autoencoder.load(join(OUTPUT_PATH, \"test\"))\n",
    "autoencoder.eval()\n",
    "\n",
    "# load results\n",
    "test_result = pt.load(join(OUTPUT_PATH, \"test_results.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_result[\"epoch\"], test_result[\"train_loss\"], lw=1, label=\"training\")\n",
    "plt.plot(test_result[\"epoch\"], test_result[\"val_loss\"], lw=1, label=\"validation\")\n",
    "# plt.plot(test_result[\"epoch\"], test_result[\"test_loss\"], lw=1, label=\"testing\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(0, config.epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(OUTPUT_PATH, \"LOSS_\" + test_case_name + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load coordinates\n",
    "coords = pt.load(join(DATA_PATH, \"coords_interp.pt\"))\n",
    "xx, yy = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, image):\n",
    "    with pt.no_grad():\n",
    "        return model(image.unsqueeze(0)).squeeze(0).squeeze(0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "fig, axes = plt.subplots(4, 2, figsize=(4, 10))\n",
    "vmin, vmax = -1, 1\n",
    "levels = pt.linspace(vmin, vmax, 120)\n",
    "\n",
    "for i, row in enumerate(axes):\n",
    "    if i == 0:\n",
    "          row[0].set_title(\"Original\")\n",
    "          row[1].set_title(\"Encoded-Decoded\")\n",
    "\n",
    "    row[0].contourf(xx, yy, test_dataset[i*5].squeeze(0), vmin=vmin, vmax=vmax, levels = levels, extend=\"both\")\n",
    "    row[1].contourf(xx, yy, make_prediction(autoencoder, test_dataset[i]), vmin=vmin, vmax=vmax, levels = levels, extend=\"both\")\n",
    "    row[0].set_ylabel(\"Test Image {}\".format(i))\n",
    "\n",
    "    for ax in row:\n",
    "            ax.set_aspect(\"equal\")\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "fig.tight_layout()\n",
    "plt.savefig(join(OUTPUT_PATH, \"RECONSTR_\" + test_case_name + \".png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
