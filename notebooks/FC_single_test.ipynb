{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# include app directory into sys.path\n",
    "parent_dir = Path(os.path.abspath('')).parent\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "import torch as pt\n",
    "from torch.nn.functional import mse_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker \n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from flowtorch.analysis import SVD\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import utils.config as config\n",
    "from CNN_VAE.CNN_VAE import make_VAE_model\n",
    "from FC.FC_model import make_FC_model\n",
    "from utils.helper_funcs import shift_input_sequence\n",
    "from utils.DataWindow import DataWindow\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# use GPU if possible\n",
    "device = pt.device(\"cuda\") if pt.cuda.is_available() else pt.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# retrieve parameters from config\n",
    "DIM_REDUCTION = \"SVD\"       # one of (\"SVD\" / \"VAE\")\n",
    "PRED_HORIZON = config.FC_SVD_pred_horizon if DIM_REDUCTION == \"SVD\" else config.FC_VAE_pred_horizon\n",
    "N_LATENT = config.SVD_rank if DIM_REDUCTION == \"SVD\" else config.VAE_latent_size\n",
    "FC_MODEL = config.FC_SVD_single_model if DIM_REDUCTION == \"SVD\" else config.FC_VAE_single_model\n",
    "\n",
    "# define paths\n",
    "DATA_PATH = join(parent_dir, \"data\", \"single_flow_cond\")\n",
    "VAE_PATH = join(parent_dir, \"output\", \"VAE\", \"latent_study\", config.VAE_model)\n",
    "SVD_PATH = join(parent_dir, \"output\", \"SVD\")\n",
    "FC_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\", f\"pred_horizon_{PRED_HORIZON}\")\n",
    "OUTPUT_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define FC model parameters\n",
    "_, INPUT_WIDTH, HIDDEN_SIZE, N_HIDDEN_LAYERS = [int(param) for param in FC_MODEL.split(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestep and index computation, transforming to dimensionsless time\n",
    "TIMESTEP_1, TIMESTEP_2 = (INPUT_WIDTH + 9, INPUT_WIDTH + 49)\n",
    "dimless_factor = config.U_inf / (config.c_mean * config.timesteps_per_second)\n",
    "\n",
    "TIMESTEP_dimless_split = round((config.single_flow_cond_train_share * config.time_steps_per_cond) * dimless_factor, 2)\n",
    "TIMESTEP_dimless_1= round((TIMESTEP_1 + (config.single_flow_cond_train_share * config.time_steps_per_cond)) * dimless_factor, 2)\n",
    "TIMESTEP_dimless_2= round((TIMESTEP_2 + (config.single_flow_cond_train_share * config.time_steps_per_cond)) * dimless_factor, 2)\n",
    "\n",
    "# compute prediction horizons to predict timestep 1 and 2\n",
    "pred_horizon_1 = TIMESTEP_1 - INPUT_WIDTH + 1\n",
    "pred_horizon_2 = TIMESTEP_2 - INPUT_WIDTH + 1\n",
    "\n",
    "# set a prediction horizon for comparing latent and full space loss\n",
    "pred_horizon_total = int(config.time_steps_per_cond - config.single_flow_cond_train_share * config.time_steps_per_cond - INPUT_WIDTH)\n",
    "\n",
    "print(f\"Test dataset comprises timesteps {int(config.single_flow_cond_train_share * config.time_steps_per_cond)} - {config.time_steps_per_cond}.\")    \n",
    "print(f\"The FC network takes the first {INPUT_WIDTH} timesteps as input.\\n\")     \n",
    "print(f\"Predicted timestep 1 (index) is:            {TIMESTEP_1}\")\n",
    "print(f\"    which equals a dimensionless time:      {TIMESTEP_dimless_1}\")\n",
    "print(f\"    and a prediction horizon of:            {pred_horizon_1}\\n\")\n",
    "print(f\"Predicted timestep 2 (index) is:            {TIMESTEP_2}\")\n",
    "print(f\"    which equals a dimensionless time:      {TIMESTEP_dimless_2}\")\n",
    "print(f\"    and a prediction horizon of:            {pred_horizon_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_with_VAE(train, test):\n",
    "    # load pre-trained autoencoder model\n",
    "    autoencoder = make_VAE_model(\n",
    "        n_latent=config.VAE_latent_size, \n",
    "        device=device)\n",
    "    autoencoder.load(VAE_PATH)\n",
    "    autoencoder.eval()\n",
    "    decoder = autoencoder._decoder\n",
    "\n",
    "    # reduce datasets\n",
    "    train_red = autoencoder.encode_dataset(train)\n",
    "    test_red = autoencoder.encode_dataset(test)\n",
    "\n",
    "    return train_red, test_red, decoder\n",
    "\n",
    "def reduce_with_SVD(train, test):\n",
    "    # load left singular vectors U\n",
    "    U = pt.load(join(SVD_PATH, \"U.pt\"))\n",
    "    mean = pt.load(join(SVD_PATH, \"mean.pt\"))\n",
    "\n",
    "    # reduce datasets\n",
    "    train_red = pt.transpose(U[:,:config.SVD_rank], 0, 1) @ (train - mean)\n",
    "    test_red = pt.transpose(U[:,:config.SVD_rank], 0, 1) @ (test - mean)\n",
    "\n",
    "    return train_red, test_red, U[:,:config.SVD_rank], mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experimental data\n",
    "train_data_orig = pt.load(join(DATA_PATH, f\"{DIM_REDUCTION}_train.pt\"))\n",
    "test_data_orig = pt.load(join(DATA_PATH, f\"{DIM_REDUCTION}_test.pt\"))\n",
    "\n",
    "# load coordinate grids\n",
    "coords = pt.load(join(Path(DATA_PATH).parent, \"coords_interp.pt\"))\n",
    "xx, yy = coords\n",
    "\n",
    "# load pre-fitted scaler\n",
    "latent_scaler = pt.load(join(FC_PATH, \"scaler.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress dataset into reduced state either by VAE or SVD\n",
    "if DIM_REDUCTION == \"VAE\":\n",
    "    train_red, test_red, decoder = reduce_with_VAE(train_data_orig, test_data_orig)\n",
    "elif DIM_REDUCTION == \"SVD\":\n",
    "    train_red, test_red, U, mean = reduce_with_SVD(train_data_orig, test_data_orig)\n",
    "    test_data_orig = test_data_orig.unflatten(dim=0, sizes=config.target_resolution)\n",
    "else:\n",
    "    raise ValueError(\"Unknown DIM_REDUCTION\")\n",
    "\n",
    "print(train_red.shape, test_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed reduced and scaled dataset into DataWindow class to create TimeSeriesTensorDatasets\n",
    "data_window = DataWindow(train=latent_scaler.scale(train_red), test=latent_scaler.scale(test_red), input_width=INPUT_WIDTH, pred_horizon=pred_horizon_total)\n",
    "input_idx, target_idx = data_window.rolling_window(test_red.shape[1])\n",
    "target_idx = target_idx.tolist()\n",
    "\n",
    "print(f\"Input indices of first window range from:           {input_idx[0][0]} to {input_idx[0][-1]}\")\n",
    "print(f\"Target indices of first window range from:          {target_idx[0][0]} to {target_idx[0][-1]}\")\n",
    "print(f\"Number of possible windows:                            {len(input_idx)}\")\n",
    "\n",
    "test_windows = data_window.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create FC model and load model state dict\n",
    "FC_model = make_FC_model(\n",
    "    latent_size=N_LATENT,\n",
    "    input_width=INPUT_WIDTH, \n",
    "    hidden_size=HIDDEN_SIZE, \n",
    "    n_hidden_layers=N_HIDDEN_LAYERS\n",
    ")\n",
    "FC_model.load(join(FC_PATH, FC_MODEL + \".pt\"))\n",
    "FC_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Mode Coefficient 1 of train and test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mode coeffs\n",
    "fig = plt.figure(figsize=(9, 2))\n",
    "plt.plot(pt.linspace(0, TIMESTEP_dimless_split, train_red.shape[1]), train_red.mean(dim=0), linewidth=0.8)\n",
    "plt.plot(pt.linspace(TIMESTEP_dimless_split + dimless_factor, TIMESTEP_dimless_split / config.single_flow_cond_train_share, test_red.shape[1]), test_red.mean(dim=0), linewidth=0.8)\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"$\\\\tau$\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_train_test_split.png\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize losses\n",
    "latent_loss = []\n",
    "orig_loss = []\n",
    "preds_new = pt.zeros((N_LATENT, pred_horizon_total))\n",
    "\n",
    "with pt.no_grad():\n",
    "    inputs, targets = test_windows[0]\n",
    "    inputs = pt.transpose(inputs, 0, 1).flatten(0, 1).unsqueeze(0).to(device)\n",
    "    targets = targets.unsqueeze(0).to(device)\n",
    "\n",
    "    # autoregressive prediction loop\n",
    "    for step in range(pred_horizon_total):\n",
    "        # shift input sequence by one: add last prediction while discarding first input\n",
    "        if step != 0:\n",
    "            inputs = shift_input_sequence(orig_seq=inputs, new_pred=pred)\n",
    "        \n",
    "        pred = FC_model(inputs)\n",
    "\n",
    "        preds_new[:, step] = pred\n",
    "\n",
    "        #print(pred.shape)\n",
    "        latent_loss.append(mse_loss(targets[:, :, step], pred))\n",
    "\n",
    "        # re-scaling\n",
    "        pred_rescaled = latent_scaler.rescale(pred)\n",
    "\n",
    "        # expand to full space either by VAE or SVD\n",
    "        if DIM_REDUCTION == \"VAE\":\n",
    "            # forward pass through decoder\n",
    "            pred_orig = decoder(pred_rescaled.unsqueeze(0)).squeeze().detach() \n",
    "        else:\n",
    "            # matrix multiplication with U, followed by adding back the temporal mean\n",
    "            pred_orig = (U @ pred_rescaled.permute(1, 0) + mean).squeeze().unflatten(dim=0, sizes=config.target_resolution)\n",
    "\n",
    "        orig_loss.append(mse_loss(test_data_orig[:, :, target_idx[0][step]], pred_orig))\n",
    "\n",
    "        # if step of specific timestep reached, save to a variable\n",
    "        if step == pred_horizon_1 - 1:\n",
    "            pred_1 = pred_orig\n",
    "        if step == pred_horizon_2 - 1:\n",
    "            pred_2 = pred_orig\n",
    "\n",
    "# compute\n",
    "MSE_1 = (test_data_orig[:, :, TIMESTEP_1] - pred_1)**2\n",
    "MSE_2 = (test_data_orig[:, :, TIMESTEP_2] - pred_2)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Mode Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mode_coeffs = 4\n",
    "fig, ax = plt.subplots(n_mode_coeffs, 1, sharey=False, sharex = True, figsize=(10, n_mode_coeffs)) #figsize =config.standard_figsize_2)\n",
    "\n",
    "for i in range(n_mode_coeffs):\n",
    "    ax[i].plot(range(1, pred_horizon_total + 1), targets[0, i, :pred_horizon_total], label=f\"true mode coefficient\", color=\"black\")\n",
    "    ax[i].plot(range(1, pred_horizon_total + 1), preds_new[i, :pred_horizon_total], label=f\"predicted mode coefficient\", ls=\"--\", color=\"cornflowerblue\")\n",
    "    ax[i].set_yticklabels([])\n",
    "    ax[i].set_yticks([])\n",
    "    ax[i].set_ylabel(f\"Mode {i + 1}\")\n",
    "\n",
    "ax[0].legend(loc='upper center', bbox_to_anchor=(0.5, 1.7), ncol=2)      \n",
    "ax[n_mode_coeffs - 1].set_xlabel(\"number of autoregressive predictions\")        \n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_modecoeffs.png\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Latent vs. Full Space Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(1, 1, figsize=config.orig_vs_latent_loss_figsize)\n",
    "plt.plot(range(1, pred_horizon_total + 1), latent_loss, ls=\"--\", label=\"reduced space loss\", color=\"yellowgreen\")\n",
    "plt.plot(range(1, pred_horizon_total + 1), orig_loss, label=\"full space loss\", color=\"darkolivegreen\")\n",
    "plt.ylabel(\"Test MSE\")\n",
    "plt.xlabel(\"number of autoregressive predictions\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(config.plot_lims_orig_vs_latent_loss)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout\n",
    "plt.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_origvslatentloss.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct $c_p$-snapshot for timestep 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "vmin_cp, vmax_cp = config.plot_lims_cp\n",
    "vmin_MSE, vmax_MSE = config.plot_lims_MSE_reconstruction\n",
    "levels_cp = pt.linspace(vmin_cp, vmax_cp, 120)\n",
    "levels_MSE = pt.linspace(vmin_MSE, vmax_MSE, 120)\n",
    "\n",
    "ax1.contourf(xx, yy, test_data_orig[:, :, TIMESTEP_1], vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "ax2.contourf(xx, yy, pred_1, vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "cont = ax3.contourf(xx, yy, MSE_1, vmin=vmin_MSE, vmax=vmax_MSE, levels=levels_MSE)\n",
    "\n",
    "ax1.set_title(\"Ground Truth\")\n",
    "ax2.set_title(DIM_REDUCTION + \"-FC\" if DIM_REDUCTION == \"SVD\" else \"CNN-VAE-FC\")\n",
    "\n",
    "fig.subplots_adjust(right=0.95)\n",
    "cax = fig.add_axes([0.99, 0.283, 0.03, 0.424])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"Squarred Error\")\n",
    "cbar.formatter = ticker.FormatStrFormatter(f'%.{3}f')\n",
    "\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_timestep_reconstr.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct $c_p$-snapshot for timestep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "vmin_cp, vmax_cp = config.plot_lims_cp\n",
    "vmin_MSE, vmax_MSE = config.plot_lims_MSE_reconstruction\n",
    "levels_cp = pt.linspace(vmin_cp, vmax_cp, 120)\n",
    "levels_MSE = pt.linspace(vmin_MSE, vmax_MSE, 120)\n",
    "\n",
    "ax1.contourf(xx, yy, test_data_orig[:, :, TIMESTEP_2], vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "ax2.contourf(xx, yy, pred_2, vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "cont = ax3.contourf(xx, yy, MSE_2, vmin=vmin_MSE, vmax=vmax_MSE, levels=levels_MSE)\n",
    "\n",
    "ax1.set_title(\"Ground Truth\")\n",
    "ax2.set_title(DIM_REDUCTION + \"-FC\" if DIM_REDUCTION == \"SVD\" else \"CNN-VAE-FC\")\n",
    "\n",
    "fig.subplots_adjust(right=0.95)\n",
    "cax = fig.add_axes([0.99, 0.283, 0.03, 0.424])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"Squarred Error\")\n",
    "cbar.formatter = ticker.FormatStrFormatter(f'%.{3}f')\n",
    "\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_timestep_2_reconstr.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reconstr = []\n",
    "pred_horizon = pred_horizon_total\n",
    "\n",
    "with pt.no_grad():\n",
    "    inputs, _ = test_windows[0]\n",
    "\n",
    "    # add batch dimension with unsqueeze(0)\n",
    "    inputs = inputs.flatten().unsqueeze(0).to(device)\n",
    "\n",
    "    for step in range(pred_horizon):\n",
    "        # shift input sequence by one: add last prediction while discarding first input\n",
    "        if step != 0:\n",
    "            inputs = shift_input_sequence(orig_seq=inputs, new_pred=pred)\n",
    "\n",
    "        # time-evolution (autoregressive)\n",
    "        pred = FC_model(inputs)\n",
    "\n",
    "        # re-scaling\n",
    "        pred_rescaled = latent_scaler.rescale(pred)\n",
    "\n",
    "        # expand to full space either by VAE or SVD\n",
    "        if DIM_REDUCTION == \"VAE\":\n",
    "            # forward pass through decoder\n",
    "            pred_orig = decoder(pred_rescaled.unsqueeze(0)).squeeze().detach() \n",
    "        else:\n",
    "            # matrix multiplication with U, followed by adding back the temporal mean\n",
    "            pred_orig = (U @ pred_rescaled.permute(1, 0) + mean).squeeze().unflatten(dim=0, sizes=config.target_resolution)\n",
    "\n",
    "        test_reconstr.append(pred_orig)\n",
    "\n",
    "test_reconstr = pt.stack(test_reconstr, dim=2)\n",
    "test_original = test_data_orig[:,:,INPUT_WIDTH:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create animations of the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE = (test_original - test_reconstr)**2\n",
    "\n",
    "# fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(6, 2.5))\n",
    "# vmin_cp, vmax_cp = config.plot_lims_cp\n",
    "# vmin_MSE, vmax_MSE = config.plot_lims_MSE_reconstruction\n",
    "# levels_cp = pt.linspace(vmin_cp, vmax_cp, 120)\n",
    "# levels_MSE = pt.linspace(vmin_MSE, vmax_MSE, 120)\n",
    "\n",
    "# def update(frame):\n",
    "#     ax1.clear()\n",
    "#     ax2.clear()\n",
    "#     ax3.clear()\n",
    "    \n",
    "#     ax1.contourf(xx, yy, test_original[:, :, frame], vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "#     ax2.contourf(xx, yy, test_reconstr[:, :, frame], vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "#     cont = ax3.contourf(xx, yy, SE[:, :, frame], vmin=vmin_MSE, vmax=vmax_MSE, levels=levels_MSE)\n",
    "\n",
    "#     ax1.set_title(\"Ground Truth\")\n",
    "#     ax2.set_title(DIM_REDUCTION + \"-FC\" if DIM_REDUCTION == \"SVD\" else \"CNN-VAE-FC\")\n",
    "\n",
    "#     for ax in [ax1, ax2, ax3]:\n",
    "#         ax.set_aspect(\"equal\")\n",
    "#         ax.set_xticklabels([])\n",
    "#         ax.set_yticklabels([])\n",
    "#         ax.set_yticks([])\n",
    "#         ax.set_xticks([])\n",
    "\n",
    "# ani = animation.FuncAnimation(fig, update, frames=SE.shape[2], interval=100)\n",
    "# ani.save(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_reconstruction.gif\"), writer='pillow')\n",
    "# plt.close(fig)\n",
    "# HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Power Spectra of POD Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten original and reconstructed test dataset\n",
    "test_original = test_original.flatten(0,1)\n",
    "test_reconstr = test_reconstr.flatten(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_original= SVD(test_original - test_original.mean(dim=1).unsqueeze(-1), rank=1e5)\n",
    "V_original = svd_original.V\n",
    "\n",
    "svd_reconstr = SVD(test_reconstr - test_reconstr.mean(dim=1).unsqueeze(-1), rank=1e5)\n",
    "V_reconstr = svd_reconstr.V\n",
    "\n",
    "N = test_original.shape[1]\n",
    "num_modes = 6\n",
    "sample_rate = 2000          # [Hz]\n",
    "y_lims = config.plot_lims_power_spectra_single\n",
    "psd_mse = []\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=config.power_sepctra_figsize, sharex=True)\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        # Calculate the mode index and retrieve mode coefficients\n",
    "        mode = row * 2 + col                   \n",
    "        original_mode_coeffs = V_original[:, mode].numpy()\n",
    "        reconstr_mode_coeffs = V_reconstr[:, mode].numpy()\n",
    "\n",
    "        # Compute FFT and PSD\n",
    "        original_fft = fft(original_mode_coeffs)\n",
    "        original_psd = np.abs(original_fft)**2 / len(original_fft)\n",
    "        reconstr_fft = fft(reconstr_mode_coeffs)\n",
    "        reconstr_psd = np.abs(reconstr_fft)**2 / len(reconstr_fft)\n",
    "\n",
    "        psd_mse.append(mse_loss(pt.from_numpy(original_psd), pt.from_numpy(reconstr_psd)))\n",
    "\n",
    "        # Frequency values for plotting\n",
    "        freq = fftfreq(len(original_mode_coeffs), d=1/sample_rate)* config.c_mean / config.U_inf\n",
    "\n",
    "        # Use only the positive frequencies (discard negative frequency half)\n",
    "        freq = freq[:len(freq)//2]\n",
    "        original_psd = original_psd[:len(original_psd)//2]\n",
    "        reconstr_psd = reconstr_psd[:len(reconstr_psd)//2]\n",
    "\n",
    "        # Plot the power spectra\n",
    "        ax[row, col].semilogy(freq, original_psd, linewidth=0.5, color=\"black\", label=\"Experimental Data\")\n",
    "        ax[row, col].semilogy(freq, reconstr_psd, linewidth=0.7, color=\"cornflowerblue\", linestyle='dashed', label=DIM_REDUCTION + \"-FC\" if DIM_REDUCTION == \"SVD\" else \"CNN-VAE-FC\")\n",
    "        ax[row, col].set_title(f\"Mode Coefficient {mode + 1}\")\n",
    "        ax[row, col].grid()\n",
    "        ax[row, col].set_yticklabels([])\n",
    "        ax[row, col].set_yticks([])\n",
    "        ax[row, col].set_ylim(y_lims)\n",
    "\n",
    "        \n",
    "ax[2, 0].set_xlabel(rf\"Strouhal number $St$\")\n",
    "ax[2, 1].set_xlabel(rf\"Strouhal number $St$\")\n",
    "ax[2, 0].legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_power_spectra.png\"), bbox_inches=\"tight\")\n",
    "\n",
    "print(\"MSE is:                  \", sum(psd_mse) / len(psd_mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
