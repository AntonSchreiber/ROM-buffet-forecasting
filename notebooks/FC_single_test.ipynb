{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# include app directory into sys.path\n",
    "parent_dir = Path(os.path.abspath('')).parent\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "import torch as pt\n",
    "from torch.nn.functional import mse_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker \n",
    "from flowtorch.analysis import SVD\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import utils.config as config\n",
    "from CNN_VAE.CNN_VAE import make_VAE_model\n",
    "from FC.FC_model import make_FC_model\n",
    "from utils.helper_funcs import shift_input_sequence\n",
    "from utils.DataWindow import DataWindow\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# use GPU if possible\n",
    "device = pt.device(\"cuda\") if pt.cuda.is_available() else pt.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# define prediction horizon and type of dimensionality reduction\n",
    "PRED_HORIZON = 4\n",
    "DIM_REDUCTION = \"SVD\"       # one of (\"SVD\" / \"VAE\")\n",
    "N_LATENT = config.SVD_rank if DIM_REDUCTION == \"SVD\" else config.VAE_latent_size\n",
    "FC_MODEL = config.FC_SVD_single_model if DIM_REDUCTION == \"SVD\" else config.FC_VAE_single_model\n",
    "\n",
    "# define paths\n",
    "DATA_PATH = join(parent_dir, \"data\", \"single_flow_cond\")\n",
    "VAE_PATH = join(parent_dir, \"output\", \"VAE\", \"latent_study\", config.VAE_model)\n",
    "SVD_PATH = join(parent_dir, \"output\", \"SVD\", \"U.pt\")\n",
    "FC_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\", f\"pred_horizon_{PRED_HORIZON}\")\n",
    "OUTPUT_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestep and index computation, transforming to dimensionsless time\n",
    "TIMESTEP_1, TIMESTEP_2 = (35, 43)\n",
    "TIMESTEP_dimless_1= round(((TIMESTEP_1 + (config.single_flow_cond_train_share * config.time_steps_per_cond)) * config.U_inf) / (config.c_mean * config.timesteps_per_second), 2)\n",
    "TIMESTEP_dimless_2= round(((TIMESTEP_2 + (config.single_flow_cond_train_share * config.time_steps_per_cond))  * config.U_inf) / (config.c_mean * config.timesteps_per_second), 2)\n",
    "\n",
    "# compute prediction horizons to predict timestep 1 and 2\n",
    "pred_horizon_1 = TIMESTEP_1 - config.input_width + 1\n",
    "pred_horizon_2 = TIMESTEP_2 - config.input_width + 1\n",
    "\n",
    "# set a prediction horizon for comparing latent and full space loss\n",
    "pred_horizon_total = 32\n",
    "\n",
    "print(f\"Test dataset comprises timesteps {int(config.single_flow_cond_train_share * config.time_steps_per_cond)} - {config.time_steps_per_cond}.\")    \n",
    "print(f\"The FC network takes the first {config.input_width} timesteps as input.\\n\")     \n",
    "print(f\"Predicted timestep 1 (index) is:            {TIMESTEP_1}\")\n",
    "print(f\"    which equals a dimensionless time:      {TIMESTEP_dimless_1}\")\n",
    "print(f\"    and a prediction horizon of:            {pred_horizon_1}\\n\")\n",
    "print(f\"Predicted timestep 2 (index) is:            {TIMESTEP_2}\")\n",
    "print(f\"    which equals a dimensionless time:      {TIMESTEP_dimless_2}\")\n",
    "print(f\"    and a prediction horizon of:            {pred_horizon_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_with_VAE(train, test):\n",
    "    # load pre-trained autoencoder model\n",
    "    autoencoder = make_VAE_model(\n",
    "        n_latent=config.VAE_latent_size, \n",
    "        device=device)\n",
    "    autoencoder.load(VAE_PATH)\n",
    "    autoencoder.eval()\n",
    "    decoder = autoencoder._decoder\n",
    "\n",
    "    # reduce datasets\n",
    "    train_red = autoencoder.encode_dataset(train)\n",
    "    test_red = autoencoder.encode_dataset(test)\n",
    "\n",
    "    return train_red, test_red, decoder\n",
    "\n",
    "def reduce_with_SVD(train, test):\n",
    "    # load left singular vectors U\n",
    "    U = pt.load(SVD_PATH)\n",
    "\n",
    "    # reduce datasets\n",
    "    train_red = pt.transpose(U[:,:config.SVD_rank], 0, 1) @ (train - train.mean(dim=1).unsqueeze(-1))\n",
    "    test_red = pt.transpose(U[:,:config.SVD_rank], 0, 1) @ (test - test.mean(dim=1).unsqueeze(-1))\n",
    "\n",
    "    return train_red, test_red, U[:,:config.SVD_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experimental data\n",
    "train_data_orig = pt.load(join(DATA_PATH, f\"{DIM_REDUCTION}_train.pt\"))\n",
    "test_data_orig = pt.load(join(DATA_PATH, f\"{DIM_REDUCTION}_test.pt\"))\n",
    "\n",
    "# load coordinate grids\n",
    "coords = pt.load(join(Path(DATA_PATH).parent, \"coords_interp.pt\"))\n",
    "xx, yy = coords\n",
    "\n",
    "# load pre-fitted scaler\n",
    "latent_scaler = pt.load(join(FC_PATH, \"scaler.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress dataset into reduced state either by VAE or SVD\n",
    "if DIM_REDUCTION == \"VAE\":\n",
    "    train_red, test_red, decoder = reduce_with_VAE(train_data_orig, test_data_orig)\n",
    "elif DIM_REDUCTION == \"SVD\":\n",
    "    train_red, test_red, U = reduce_with_SVD(train_data_orig, test_data_orig)\n",
    "    test_data_orig = test_data_orig.unflatten(dim=0, sizes=config.target_resolution)\n",
    "else:\n",
    "    raise ValueError(\"Unknown DIM_REDUCTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed reduced and scaled dataset into DataWindow class to create TimeSeriesTensorDatasets\n",
    "data_window = DataWindow(train=latent_scaler.scale(train_red), test=latent_scaler.scale(test_red), input_width=config.input_width, pred_horizon=pred_horizon_total)\n",
    "_, target_idx = data_window.rolling_window(test_red.shape[1])\n",
    "target_idx = target_idx.tolist()\n",
    "\n",
    "test_windows = data_window.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define FC model parameters\n",
    "_, INPUT_WIDTH, HIDDEN_SIZE, N_HIDDEN_LAYERS = [int(param) for param in FC_MODEL.split(\"_\")]\n",
    "\n",
    "# create FC model and load model state dict\n",
    "FC_model = make_FC_model(\n",
    "    latent_size=N_LATENT,\n",
    "    input_width=INPUT_WIDTH, \n",
    "    hidden_size=HIDDEN_SIZE, \n",
    "    n_hidden_layers=N_HIDDEN_LAYERS\n",
    ")\n",
    "FC_model.load(join(FC_PATH, FC_MODEL + \".pt\"))\n",
    "FC_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize losses\n",
    "latent_loss = []\n",
    "orig_loss = []\n",
    "\n",
    "with pt.no_grad():\n",
    "    inputs, targets = test_windows[0]\n",
    "    # add batch dimension with unsqueeze(0)\n",
    "    inputs = inputs.flatten().unsqueeze(0).to(device)\n",
    "    targets = targets.unsqueeze(0).to(device)\n",
    "\n",
    "    for step in range(pred_horizon_total):\n",
    "        # shift input sequence by one: add last prediction while discarding first input\n",
    "        if step != 0:\n",
    "            inputs = shift_input_sequence(orig_seq=inputs, new_pred=pred)\n",
    "\n",
    "        # time-evolution (autoregressive)\n",
    "        pred = FC_model(inputs)\n",
    "        latent_loss.append(mse_loss(targets[:, :, step], pred))\n",
    "\n",
    "        # re-scaling\n",
    "        pred_rescaled = latent_scaler.rescale(pred)\n",
    "\n",
    "        # expand to full space either by VAE or SVD\n",
    "        if DIM_REDUCTION == \"VAE\":\n",
    "            # forward pass through decoder\n",
    "            pred_orig = decoder(pred_rescaled.unsqueeze(0)).squeeze().detach() \n",
    "        else:\n",
    "            # matrix multiplication with U, followed by adding back the temporal mean\n",
    "            pred_orig = (U @ pred_rescaled.permute(1, 0) + test_data_orig.flatten(0, 1).mean(dim=1).unsqueeze(-1)).squeeze().unflatten(dim=0, sizes=config.target_resolution)\n",
    "\n",
    "        orig_loss.append(mse_loss(test_data_orig[:, :, target_idx[0][step]], pred_orig))\n",
    "\n",
    "        # if step of specific timestep reached, save to a variable\n",
    "        if step == pred_horizon_1 - 1:\n",
    "            pred_1 = pred_orig\n",
    "        if step == pred_horizon_2 - 1:\n",
    "            pred_2 = pred_orig\n",
    "\n",
    "# compute\n",
    "MSE_1 = (test_data_orig[:, :, TIMESTEP_1] - pred_1)**2\n",
    "MSE_2 = (test_data_orig[:, :, TIMESTEP_2] - pred_2)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Latent vs. Full Space Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(1, 1, figsize=config.standard_figsize_1)\n",
    "plt.plot(range(1, pred_horizon_total + 1), latent_loss, label=\"reduced space loss\")\n",
    "plt.plot(range(1, pred_horizon_total + 1), orig_loss, label=\"full space loss\")\n",
    "plt.ylabel(\"Test MSE\")\n",
    "plt.xlabel(\"number of autoregressive predictions\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_origvslatentloss.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct $c_p$-snapshot for timestep 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "vmin_cp, vmax_cp = config.plot_lims_cp\n",
    "vmin_MSE, vmax_MSE = config.plot_lims_MSE_reconstruction\n",
    "levels_cp = pt.linspace(vmin_cp, vmax_cp, 120)\n",
    "levels_MSE = pt.linspace(vmin_MSE, vmax_MSE, 120)\n",
    "\n",
    "ax1.contourf(xx, yy, test_data_orig[:, :, TIMESTEP_1], vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "ax2.contourf(xx, yy, pred_1, vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "cont = ax3.contourf(xx, yy, MSE_1, vmin=vmin_MSE, vmax=vmax_MSE, levels=levels_MSE)\n",
    "\n",
    "ax1.set_title(\"Ground Truth\")\n",
    "ax2.set_title(DIM_REDUCTION + \"-FC\" if DIM_REDUCTION == \"SVD\" else \"CNN-VAE-FC\")\n",
    "\n",
    "fig.subplots_adjust(right=0.95)\n",
    "cax = fig.add_axes([0.99, 0.283, 0.03, 0.424])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"Squarred Error\")\n",
    "cbar.formatter = ticker.FormatStrFormatter(f'%.{3}f')\n",
    "\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_timestep_reconstr.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct $c_p$-snapshot for timestep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "vmin_cp, vmax_cp = config.plot_lims_cp\n",
    "vmin_MSE, vmax_MSE = config.plot_lims_MSE_reconstruction\n",
    "levels_cp = pt.linspace(vmin_cp, vmax_cp, 120)\n",
    "levels_MSE = pt.linspace(vmin_MSE, vmax_MSE, 120)\n",
    "\n",
    "ax1.contourf(xx, yy, test_data_orig[:, :, TIMESTEP_2], vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "ax2.contourf(xx, yy, pred_2, vmin=vmin_cp, vmax=vmax_cp, levels=levels_cp)\n",
    "cont = ax3.contourf(xx, yy, MSE_2, vmin=vmin_MSE, vmax=vmax_MSE, levels=levels_MSE)\n",
    "\n",
    "ax1.set_title(\"Ground Truth\")\n",
    "ax2.set_title(DIM_REDUCTION + \"-FC\" if DIM_REDUCTION == \"SVD\" else \"CNN-VAE-FC\")\n",
    "\n",
    "fig.subplots_adjust(right=0.95)\n",
    "cax = fig.add_axes([0.99, 0.283, 0.03, 0.424])\n",
    "cbar = fig.colorbar(cont, cax=cax,label = \"Squarred Error\")\n",
    "cbar.formatter = ticker.FormatStrFormatter(f'%.{3}f')\n",
    "\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_timestep_2_reconstr.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reconstr = []\n",
    "pred_horizon = int(config.time_steps_per_cond - config.single_flow_cond_train_share * config.time_steps_per_cond - config.input_width)\n",
    "\n",
    "with pt.no_grad():\n",
    "    inputs, _ = test_windows[0]\n",
    "\n",
    "    # add batch dimension with unsqueeze(0)\n",
    "    inputs = inputs.flatten().unsqueeze(0).to(device)\n",
    "\n",
    "    for step in range(pred_horizon):\n",
    "        # shift input sequence by one: add last prediction while discarding first input\n",
    "        if step != 0:\n",
    "            inputs = shift_input_sequence(orig_seq=inputs, new_pred=pred)\n",
    "\n",
    "        # time-evolution (autoregressive)\n",
    "        pred = FC_model(inputs)\n",
    "\n",
    "        # re-scaling\n",
    "        pred_rescaled = latent_scaler.rescale(pred)\n",
    "\n",
    "        # expand to full space either by VAE or SVD\n",
    "        if DIM_REDUCTION == \"VAE\":\n",
    "            # forward pass through decoder\n",
    "            pred_orig = decoder(pred_rescaled.unsqueeze(0)).squeeze().detach() \n",
    "        else:\n",
    "            # matrix multiplication with U, followed by adding back the temporal mean\n",
    "            pred_orig = (U @ pred_rescaled.permute(1, 0) + test_data_orig.flatten(0, 1).mean(dim=1).unsqueeze(-1)).squeeze().unflatten(dim=0, sizes=config.target_resolution)\n",
    "\n",
    "        test_reconstr.append(pred_orig)\n",
    "\n",
    "test_reconstr = pt.stack(test_reconstr, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Power Spectra of POD Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten original and reconstructed test dataset\n",
    "test_original = test_data_orig[:,:,config.input_width:].flatten(0,1)\n",
    "test_reconstr = test_reconstr.flatten(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_original= SVD(test_original - test_original.mean(dim=1).unsqueeze(-1), rank=1e5)\n",
    "V_original = svd_original.V\n",
    "\n",
    "svd_reconstr = SVD(test_reconstr - test_reconstr.mean(dim=1).unsqueeze(-1), rank=1e5)\n",
    "V_reconstr = svd_reconstr.V\n",
    "\n",
    "N = test_original.shape[1]\n",
    "num_modes = 4\n",
    "sample_rate = 2000          # [Hz]\n",
    "y_lims = [1e-7, 1e-1]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 5), sharex=True)\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        # Calculate the mode index and retrieve mode coefficients\n",
    "        mode = row * 2 + col                   \n",
    "        original_mode_coeffs = V_original[:, mode].numpy()\n",
    "        reconstr_mode_coeffs = V_reconstr[:, mode].numpy()\n",
    "\n",
    "        # Compute FFT and PSD\n",
    "        original_fft = fft(original_mode_coeffs)\n",
    "        original_psd = np.abs(original_fft)**2 / len(original_fft)\n",
    "        reconstr_fft = fft(reconstr_mode_coeffs)\n",
    "        reconstr_psd = np.abs(reconstr_fft)**2 / len(reconstr_fft)\n",
    "\n",
    "        # Frequency values for plotting\n",
    "        freq = fftfreq(len(original_mode_coeffs), d=1/sample_rate)* config.U_inf / config.a\n",
    "\n",
    "        # Use only the positive frequencies (discard negative frequency half)\n",
    "        freq = freq[:len(freq)//2]\n",
    "        original_psd = original_psd[:len(original_psd)//2]\n",
    "        reconstr_psd = reconstr_psd[:len(reconstr_psd)//2]\n",
    "\n",
    "        # Plot the power spectra\n",
    "        ax[row, col].semilogy(freq, original_psd, linewidth=0.5, color=\"black\", label=\"Experimental Data\")\n",
    "        ax[row, col].semilogy(freq, reconstr_psd, linewidth=0.7, color=\"cornflowerblue\", linestyle='dashed', label=DIM_REDUCTION + \"-FC\" if DIM_REDUCTION == \"SVD\" else \"CNN-VAE-FC\")\n",
    "        ax[row, col].set_title(f\"POD Mode {mode + 1}\")\n",
    "        ax[row, col].grid()\n",
    "        ax[row, col].set_yticklabels([])\n",
    "        ax[row, col].set_yticks([])\n",
    "        ax[row, col].set_ylim(y_lims)\n",
    "\n",
    "        \n",
    "ax[1, 0].set_xlabel(rf\"Reduced Frequency $\\omega$\")\n",
    "ax[1, 1].set_xlabel(rf\"Reduced Frequency $\\omega$\")\n",
    "ax[1,0].legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_power_spectra.png\"), bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
