{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# include app directory into sys.path\n",
    "parent_dir = Path(os.path.abspath('')).parent\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "import torch as pt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import config\n",
    "\n",
    "# increase plot resolution\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# retrieve parameters from config\n",
    "DIM_REDUCTION = \"SVD\"       # one of (\"SVD\" / \"VAE\")\n",
    "PRED_HORIZON = config.FC_SVD_pred_horizon if DIM_REDUCTION == \"SVD\" else config.FC_VAE_pred_horizon\n",
    "EPOCHS = config.FC_SVD_single_epochs if DIM_REDUCTION == \"SVD\" else config.FC_VAE_single_epochs\n",
    "\n",
    "# define paths\n",
    "FC_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\", f\"pred_horizon_{PRED_HORIZON}\")\n",
    "OUTPUT_PATH = join(parent_dir, \"output\", \"FC\", \"single\", DIM_REDUCTION, \"param_study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate study results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load study results\n",
    "study_results = pt.load(join(FC_PATH, \"study_results.pt\"))\n",
    "param_combinations = list(study_results.keys())\n",
    "\n",
    "# find parameter combinations of study and extract test loss\n",
    "hidden_size = np.unique([int(param_set.split('_')[1]) for param_set in param_combinations])\n",
    "n_hidden = np.unique([int(param_set.split('_')[2]) for param_set in param_combinations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of test loss for each epoch for each parameter combination\n",
    "train_means = {}\n",
    "test_means = {}\n",
    "best_models = {}\n",
    "\n",
    "for param_combination in study_results:\n",
    "    all_test_losses = []\n",
    "    all_train_losses = []\n",
    "    for df in study_results[param_combination]:\n",
    "        all_test_losses.append(df[\"val_loss\"])\n",
    "        all_train_losses.append(df[\"train_loss\"])\n",
    "\n",
    "    # identify model with lowest test loss for each parameter combination\n",
    "    final_losses = [test_loss[-10:].mean() for test_loss in all_test_losses]\n",
    "    best_models[str(final_losses.index(min(final_losses)) + 1) + \"_\" + param_combination] = min(final_losses)\n",
    "    \n",
    "    # Pad shorter training sequences with NaNs to ensure equal lengths\n",
    "    all_test_losses_padded = np.array([np.pad(loss, (0, EPOCHS - len(loss)), mode='constant', constant_values=np.nan) for loss in all_test_losses])\n",
    "    all_train_losses_padded = np.array([np.pad(loss,(0, EPOCHS - len(loss)), mode='constant', constant_values=np.nan) for loss in all_train_losses])\n",
    "    \n",
    "    # Calculate mean and std while ignoring NaN values\n",
    "    test_means[param_combination] = np.nanmean(all_test_losses_padded, axis=0)\n",
    "    train_means[param_combination] = np.nanmean(all_train_losses_padded, axis=0)\n",
    "\n",
    "# Create the plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 3), sharey = True, sharex = True)\n",
    "\n",
    "# Plot mean training and test loss\n",
    "for size in study_results:\n",
    "    ax1.plot(np.arange(1, EPOCHS + 1), train_means[size], label=f'{size.split(\"_\")[1]} Neur., {size.split(\"_\")[2]} Layer')\n",
    "    ax2.plot(np.arange(1, EPOCHS + 1), test_means[size], label=f'{size.split(\"_\")[1]} Neur., {size.split(\"_\")[2]} Layer')\n",
    "\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_title(\"Train MSE Mean\")\n",
    "ax2.set_xlabel(\"epoch\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_title(\"Test MSE Mean\")\n",
    "#ax2.legend(loc=1, bbox_to_anchor=(1,1))\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "plt.xlim(0, EPOCHS)\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(OUTPUT_PATH, f\"{DIM_REDUCTION}_FC_single_predhor{PRED_HORIZON}_loss_mean.png\"), bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
