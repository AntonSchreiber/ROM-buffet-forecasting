{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Reconstruction Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "parent_dir = os.path.abspath(join(os.getcwd(), os.pardir))\n",
    "app_dir = join(parent_dir, \"app\")\n",
    "if app_dir not in sys.path:\n",
    "      sys.path.append(app_dir)\n",
    "\n",
    "from pathlib import Path\n",
    "import torch as pt\n",
    "from torch.utils.data import Subset\n",
    "from torch.nn.functional import mse_loss\n",
    "from CNN_VAE import ConvEncoder, ConvDecoder, Autoencoder\n",
    "from utils.training_loop import train_cnn_vae\n",
    "import utils.config as config\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pt.manual_seed(0)\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 180\n",
    "\n",
    "# use GPU if possible\n",
    "device = pt.device(\"cuda:0\") if pt.cuda.is_available() else pt.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "TIMESTEP = 2\n",
    "\n",
    "DATA_PATH = Path(os.path.abspath('')).parent / \"data\"\n",
    "OUTPUT_PATH = Path(os.path.abspath('')).parent / \"output\" / \"VAE\"\n",
    "MODEL_PATH = Path(os.path.abspath('')).parent / \"output\" / \"VAE\" / \"latent_study\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "test_dataset = pt.load(join(DATA_PATH, \"test_dataset.pt\"))\n",
    "\n",
    "# split test dataset into the two flow conditions\n",
    "X_test_1 = Subset(test_dataset,                                 # ma0.84 alpha3.00 \n",
    "                  list(range(0, int(len(test_dataset) / 2))))        \n",
    "X_test_2 = Subset(test_dataset,                                 # ma0.84 alpha5.00\n",
    "                  list(range(int(len(test_dataset) / 2), len(test_dataset))))    \n",
    "\n",
    "# make tensors from datasets\n",
    "X_test_1_tensor = pt.stack([X_test_1[i] for i in range(len(X_test_1))], dim=3).squeeze(0)\n",
    "X_test_2_tensor = pt.stack([X_test_2[i] for i in range(len(X_test_2))], dim=3).squeeze(0)\n",
    "print(X_test_1_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE and Variance Reconstruction with varying number of bottleneck neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create VAE model\n",
    "def make_VAE_model(n_latent: int = 256) -> pt.nn.Module:\n",
    "    encoder = ConvEncoder(\n",
    "        in_size=config.target_resolution,\n",
    "        n_channels=config.input_channels,\n",
    "        n_latent=config.latent_size,\n",
    "        variational=True,\n",
    "        layernorm=True\n",
    "    )\n",
    "\n",
    "    decoder = ConvDecoder(\n",
    "        in_size=config.target_resolution,\n",
    "        n_channels=config.output_channels,\n",
    "        n_latent=config.latent_size,\n",
    "        layernorm=True,\n",
    "        squash_output=True\n",
    "    )\n",
    "\n",
    "    autoencoder = Autoencoder(encoder, decoder)\n",
    "    autoencoder.to(device)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scan directory for trained models and extract paths as well as the latent size of the model\n",
    "dirs = [os.path.join(MODEL_PATH, name, name) for name in os.listdir(MODEL_PATH) if os.path.isdir(os.path.join(MODEL_PATH, name))]\n",
    "sorted_dirs = sorted(dirs, key=lambda x: int(os.path.basename(x)))\n",
    "latent_sizes = [int(os.path.basename(dir)) for dir in sorted_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to save the computed metrics\n",
    "MSE_1 = []\n",
    "MSE_2 = []\n",
    "Var1 = []\n",
    "Var2 = []\n",
    "\n",
    "# compute the total variance of test datasets\n",
    "orig_Var1 = pt.var(X_test_1_tensor)\n",
    "orig_Var2 = pt.var(X_test_2_tensor)\n",
    "\n",
    "for i, latent_size in enumerate(latent_sizes):\n",
    "    print(\"Computing metrics for autoencoder with latent size \", latent_size)\n",
    "    # load model\n",
    "    autoencoder = make_VAE_model(latent_size)\n",
    "    autoencoder.load(sorted_dirs[i])\n",
    "    autoencoder.eval()\n",
    "\n",
    "    # reconstruct test dataset 1\n",
    "    with pt.no_grad():\n",
    "        reconstructed = pt.stack([autoencoder(X_test_1[i].unsqueeze(0)).squeeze(0).detach() for i in range(len(X_test_1))], dim=3).squeeze(0)\n",
    "        \n",
    "    # compute MSE\n",
    "    MSE_1.append(mse_loss(X_test_1_tensor, reconstructed).item())\n",
    "\n",
    "    # compute variance reconstruction\n",
    "    Var1.append(((1 - ((orig_Var1 - pt.var(reconstructed)) / orig_Var1)) * 100).item())\n",
    "\n",
    "    # reconstruct test dataset 2\n",
    "    with pt.no_grad():\n",
    "        reconstructed = pt.stack([autoencoder(X_test_2[i].unsqueeze(0)).squeeze(0).detach() for i in range(len(X_test_2))], dim=3).squeeze(0)\n",
    "\n",
    "    # compute MSE\n",
    "    MSE_2.append(mse_loss(X_test_2_tensor, reconstructed).item())\n",
    "\n",
    "    # compute variance reconstruction\n",
    "    Var2.append(((1 - ((orig_Var2 - pt.var(reconstructed)) / orig_Var2)) * 100).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results and save the figure\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax1.plot(latent_sizes, MSE_1, label=\"Test Dataset 1\")\n",
    "ax1.plot(latent_sizes, MSE_2, label=\"Test Dataset 2\")\n",
    "ax1.set_title(\"MSE\")\n",
    "ax2.plot(latent_sizes, Var1, label=\"Test Dataset 1\")\n",
    "ax2.plot(latent_sizes, Var2, label=\"Test Dataset 2\")\n",
    "ax2.set_title(\"Variance Reconstruction in %\")\n",
    "ax2.set_xlabel(\"number of bottleneck neurons\")\n",
    "ax2.set_xticks(range(0, 325, 25))\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels)\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"MSE_and_Variance_with_latent_size.png\"), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal MSE distribution with varying number of bottleneck neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mini_datset:\n",
    "    timesteps = range(config.mini_test_per_cond)\n",
    "else:\n",
    "    timesteps = range(500)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (8, 3))\n",
    "    \n",
    "for i, latent_size in enumerate(latent_sizes):\n",
    "    print(\"Computing metrics for autoencoder with latent size \", latent_size)\n",
    "    # load model\n",
    "    autoencoder = make_VAE_model(latent_size)\n",
    "    autoencoder.load(sorted_dirs[i])\n",
    "    autoencoder.eval()\n",
    "\n",
    "    # reconstruct test dataset 1\n",
    "    with pt.no_grad():\n",
    "        reconstructed = pt.stack([autoencoder(X_test_1[i].unsqueeze(0)).squeeze(0).detach() for i in range(len(X_test_1))], dim=3).squeeze(0)\n",
    "\n",
    "    MSE = ((X_test_1_tensor - reconstructed)**2).mean(dim=[0, 1])\n",
    "    ax1.plot(timesteps, MSE, label=\"bottleneck neurons {}\".format(latent_size))\n",
    "\n",
    "# ax1.set_title(\"Test Dataset 1\")\n",
    "ax1.set_ylabel(\"MSE\")\n",
    "ax1.set_xlabel(\"timestep\")\n",
    "# ax1.set_yscale(\"log\")\n",
    "\n",
    "fig.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(OUTPUT_PATH, \"temporal_MSE_distribution_VAE.png\"), bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial MSE distribution with varying number of bottleneck neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates\n",
    "coords = pt.load(join(DATA_PATH, \"coords_interp.pt\"))\n",
    "xx, yy = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharey=True)\n",
    "\n",
    "for i, latent_size in enumerate([60, 110, 260]):\n",
    "    print(\"Computing metrics for autoencoder with latent size \", latent_size)\n",
    "    # load model\n",
    "    autoencoder = make_VAE_model(latent_size)\n",
    "    autoencoder.load(sorted_dirs[i])\n",
    "    autoencoder.eval()\n",
    "\n",
    "    # reconstruct test dataset 1\n",
    "    with pt.no_grad():\n",
    "        reconstructed = pt.stack([autoencoder(X_test_1[i].unsqueeze(0)).squeeze(0).detach() for i in range(len(X_test_1))], dim=3).squeeze(0)\n",
    "        \n",
    "    # compute MSE\n",
    "    MSE_1.append(mse_loss(X_test_1_tensor, reconstructed).item())\n",
    "\n",
    "    # compute variance reconstruction\n",
    "    Var1.append(((1 - ((orig_Var1 - pt.var(reconstructed)) / orig_Var1)) * 100).item())\n",
    "\n",
    "    # reconstruct test dataset 2\n",
    "    with pt.no_grad():\n",
    "        reconstructed = pt.stack([autoencoder(X_test_2[i].unsqueeze(0)).squeeze(0).detach() for i in range(len(X_test_2))], dim=3).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstructed pressure field compared to Ground Truth for two bottleneck sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
